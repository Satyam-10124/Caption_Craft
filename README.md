# Caption Craft: Empowering the Visually Impaired

**Caption Craft** is an innovative web application designed to assist visually impaired users by analyzing images and describing them through speech and text. It leverages AI-powered image processing and natural language generation to help users understand their surroundings better.

## üåü Project Overview

Caption Craft empowers visually impaired users to interact with and interpret their surroundings in a more intuitive and accessible way. The application analyzes uploaded images, provides object detection details, and narrates the scene through a conversational AI chatbot.

Key features include:
- **Image Upload and Analysis:** Users can upload images for analysis, where the app detects objects and generates a detailed caption.
- **Text-to-Speech:** Once the scene is analyzed, the application converts the description into speech for users to hear.
- **Object Detection:** The app detects various objects in the image and highlights them with bounding boxes and labels.

## üöÄ Demo

You can check out the live demo of the application here:  
**[Link to Your Project Demo]( https://Satyam-10124.github.io/Caption_Craft)**  
*(Replace this placeholder with the actual link to your project demo)*

## üõ†Ô∏è Technologies Used

- **Frontend:** 
  - HTML5, CSS3, JavaScript
  - Canvas API for image rendering
- **Backend/AI Services:** 
  - Hugging Face APIs (for object detection and captioning)
  - OpenAI Chatbot for refined image descriptions
- **Text-to-Speech:** 
  - Web Speech API for generating speech output
- **Other:** 
  - Particles.js for background effects

## üì∏ Features

1. **Image Upload:** Easily upload images for processing.
2. **Image Analysis:** Detects objects in the image and provides detailed captions.
3. **Text-to-Speech:** Describes the scene through speech, helping visually impaired users understand the content.
4. **Download Processed Image:** Users can download the processed image with annotations.
5. **Particle Background:** The site has a dynamic particle effect to enhance the user experience.

## üéØ How It Works

1. **Image Upload:** Users select an image to upload.
2. **Processing:** The app uses Hugging Face's object detection model to analyze the image.
3. **Description:** It generates a description of the image using an image captioning model.
4. **Chatbot Refinement:** The description is refined by a chatbot to make it more user-friendly.
5. **Text-to-Speech:** The final description is read aloud to the user.

## üí° Motivation

This project aims to help blind and visually impaired people navigate the world by providing an accessible solution to understanding their surroundings through technology. The goal is to create an intuitive and seamless experience for users to interact with the environment via voice.

